{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7470bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c32f8e",
   "metadata": {},
   "source": [
    "## NN based approach for electron energy regression\n",
    "\n",
    "A neural network is made with X structure from the keras framework\n",
    "\n",
    "What to implement \n",
    "* Cross-Validation\n",
    "* Hyperparameter optimisation\n",
    "\n",
    "# Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b57508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    with h5py.File(f'{name}.h5', 'r') as f:\n",
    "        filename = name.split('/')[1]\n",
    "        return pd.DataFrame(f[filename][:], dtype=np.float64)\n",
    "\n",
    "train = load_data('data/train')\n",
    "test  = load_data('data/test')\n",
    "\n",
    "# Variable list from https://www.nbi.dk/~petersen/Teaching/ML2023/InitialProject/VariableList.html\n",
    "all_variables = ['actualInteractionsPerCrossing', 'averageInteractionsPerCrossing', 'correctedActualMu', 'correctedAverageMu', 'correctedScaledActualMu', 'correctedScaledAverageMu', 'NvtxReco', 'p_nTracks', 'p_pt_track', 'p_eta', 'p_phi', 'p_charge', 'p_qOverP', 'p_z0', 'p_d0', 'p_sigmad0', 'p_d0Sig', 'p_EptRatio', 'p_dPOverP', 'p_z0theta', 'p_etaCluster', 'p_phiCluster', 'p_eCluster', 'p_rawEtaCluster', 'p_rawPhiCluster', 'p_rawECluster', 'p_eClusterLr0', 'p_eClusterLr1', 'p_eClusterLr2', 'p_eClusterLr3', 'p_etaClusterLr1', 'p_etaClusterLr2', 'p_phiClusterLr2', 'p_eAccCluster', 'p_f0Cluster', 'p_etaCalo', 'p_phiCalo', 'p_eTileGap3Cluster', 'p_cellIndexCluster', 'p_phiModCalo', 'p_etaModCalo', 'p_dPhiTH3', 'p_R12', 'p_fTG3', 'p_weta2', 'p_Reta', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_f3', 'p_Rhad', 'p_Rhad1', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_TRTPID', 'p_TRTTrackOccupancy', 'p_numberOfInnermostPixelHits', 'p_numberOfPixelHits', 'p_numberOfSCTHits', 'p_numberOfTRTHits', 'p_numberOfTRTXenonHits', 'p_chi2', 'p_ndof', 'p_SharedMuonTrack', 'p_E7x7_Lr2', 'p_E7x7_Lr3', 'p_E_Lr0_HiG', 'p_E_Lr0_LowG', 'p_E_Lr0_MedG', 'p_E_Lr1_HiG', 'p_E_Lr1_LowG', 'p_E_Lr1_MedG', 'p_E_Lr2_HiG', 'p_E_Lr2_LowG', 'p_E_Lr2_MedG', 'p_E_Lr3_HiG', 'p_E_Lr3_LowG', 'p_E_Lr3_MedG', 'p_ambiguityType', 'p_asy1', 'p_author', 'p_barys1', 'p_core57cellsEnergyCorrection', 'p_deltaEta0', 'p_deltaEta2', 'p_deltaEta3', 'p_deltaPhi0', 'p_deltaPhi1', 'p_deltaPhi2', 'p_deltaPhi3', 'p_deltaPhiFromLastMeasurement', 'p_deltaPhiRescaled0', 'p_deltaPhiRescaled1', 'p_deltaPhiRescaled3', 'p_e1152', 'p_e132', 'p_e235', 'p_e255', 'p_e2ts1', 'p_ecore', 'p_emins1', 'p_etconeCorrBitset', 'p_ethad', 'p_ethad1', 'p_f1core', 'p_f3core', 'p_maxEcell_energy', 'p_maxEcell_gain', 'p_maxEcell_time', 'p_maxEcell_x', 'p_maxEcell_y', 'p_maxEcell_z', 'p_nCells_Lr0_HiG', 'p_nCells_Lr0_LowG', 'p_nCells_Lr0_MedG', 'p_nCells_Lr1_HiG', 'p_nCells_Lr1_LowG', 'p_nCells_Lr1_MedG', 'p_nCells_Lr2_HiG', 'p_nCells_Lr2_LowG', 'p_nCells_Lr2_MedG', 'p_nCells_Lr3_HiG', 'p_nCells_Lr3_LowG', 'p_nCells_Lr3_MedG', 'p_pos', 'p_pos7', 'p_poscs1', 'p_poscs2', 'p_ptconeCorrBitset', 'p_ptconecoreTrackPtrCorrection', 'p_r33over37allcalo', 'p_topoetconeCorrBitset', 'p_topoetconecoreConeEnergyCorrection', 'p_topoetconecoreConeSCEnergyCorrection', 'p_weta1', 'p_widths1', 'p_widths2', 'p_wtots1', 'p_e233', 'p_e237', 'p_e277', 'p_e2tsts1', 'p_ehad1', 'p_emaxs1', 'p_fracs1', 'p_DeltaE', 'p_E3x5_Lr0', 'p_E3x5_Lr1', 'p_E3x5_Lr2', 'p_E3x5_Lr3', 'p_E5x7_Lr0', 'p_E5x7_Lr1', 'p_E5x7_Lr2', 'p_E5x7_Lr3', 'p_E7x11_Lr0', 'p_E7x11_Lr1', 'p_E7x11_Lr2', 'p_E7x11_Lr3', 'p_E7x7_Lr0', 'p_E7x7_Lr1' ]\n",
    "\n",
    "\n",
    "X_train = train[all_variables][:130000]\n",
    "y_train = train['Truth'][:130000]\n",
    "X_validate = train[all_variables][130000:]\n",
    "y_validate = train['Truth'][130000:]\n",
    "X_test = test[all_variables]\n",
    "\n",
    "with open('Classification_JuliusFoverskov_XGBoost_VariableList.txt','r') as f:\n",
    "    sorted_variables = [item.strip() for item in f]\n",
    "\n",
    "# Only pick 15 most important features for clustering, importances optained from permutation importance\n",
    "sorted_variables = sorted_variables[:15]\n",
    "\n",
    "X_train = X_train[sorted_variables]\n",
    "X_validate = X_validate[sorted_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d59061",
   "metadata": {},
   "source": [
    "# NN - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a426d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the network hyperparameters\n",
    "n_inputs = 15\n",
    "n_hidden1 = 10\n",
    "n_hidden2 = 10\n",
    "n_outputs = 1\n",
    "batch_norm_momentum = 0.9\n",
    "learning_rate = 0.001\n",
    "init = tf.keras.initializers.VarianceScaling(scale=1.0, mode='fan_in')\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# network structure\n",
    "nn_reg = tf.keras.models.Sequential([\n",
    "  Flatten(input_shape=(15, 1)),\n",
    "  Dense(n_hidden1, activation='ReLU'),\n",
    "  BatchNormalization(momentum=batch_norm_momentum, center=True, scale=True),\n",
    "  Dense(n_hidden2, activation='ReLU'),\n",
    "  BatchNormalization(momentum=batch_norm_momentum, center=True, scale=True),\n",
    "  Dense(n_outputs, activation='ReLU'),\n",
    "  BatchNormalization(momentum=batch_norm_momentum, center=True, scale=True)\n",
    "])\n",
    "\n",
    "nn_reg.compile(loss=mse, optimizer=SGD(learning_rate), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aeba4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "650/650 [==============================] - 2s 2ms/step - loss: 0.7991 - mse: 0.7991 - val_loss: 0.4625 - val_mse: 0.4625\n",
      "Epoch 2/6\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.1954 - val_mse: 0.1954\n",
      "Epoch 3/6\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 0.1882 - mse: 0.1882 - val_loss: 0.1882 - val_mse: 0.1882\n",
      "Epoch 4/6\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 0.1851 - mse: 0.1851 - val_loss: 0.1865 - val_mse: 0.1865\n",
      "Epoch 5/6\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 0.1844 - mse: 0.1844 - val_loss: 0.1925 - val_mse: 0.1925\n",
      "Epoch 6/6\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 0.1838 - mse: 0.1838 - val_loss: 0.1871 - val_mse: 0.1871\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 6\n",
    "batch_size = 200\n",
    "\n",
    "history = nn_reg.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d1685",
   "metadata": {},
   "source": [
    "plt.plot(np.arange(n_epochs), history.history['mse'], label = 'training')\n",
    "plt.plot(np.arange(n_epochs), history.history['val_mse'], label = 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817930fb",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "ax.plot(np.arange(n_epochs), history.history['mse'], 'ks-', label='train accuracy')\n",
    "ax.plot(np.arange(n_epochs), history.history['val_mse'], 'bs-', label='validation accuracy')\n",
    "ax.set_ylabel('mse')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "031150b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5021/5021 [==============================] - 5s 928us/step\n"
     ]
    }
   ],
   "source": [
    "a = nn_reg.predict(X_test[sorted_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeeb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b704a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
