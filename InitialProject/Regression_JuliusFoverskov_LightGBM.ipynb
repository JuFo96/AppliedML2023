{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8857f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "import lightgbm as lgb \n",
    "\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f7aa85",
   "metadata": {},
   "source": [
    "## NN based approach for electron energy regression\n",
    "\n",
    "A neural network is made with X structure from the keras framework\n",
    "\n",
    "What to implement \n",
    "* Cross-Validation\n",
    "* Hyperparameter optimisation\n",
    "\n",
    "# Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc94ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    with h5py.File(f'{name}.h5', 'r') as f:\n",
    "        filename = name.split('/')[1]\n",
    "        return pd.DataFrame(f[filename][:], dtype=np.float64)\n",
    "\n",
    "train = load_data('data/train')\n",
    "test  = load_data('data/test')\n",
    "\n",
    "# Select only true electrons for energy regression\n",
    "train_mask = train['Truth'][:130000] == 1\n",
    "validate_mask = train['Truth'][130000:] == 1\n",
    "\n",
    "#scaler_train = preprocessing.StandardScaler().fit(train)\n",
    "#scaler_test = preprocessing.StandardScaler().fit(test)\n",
    "#train = pd.DataFrame(scaler_train.transform(train), columns = train.columns)\n",
    "#test = pd.DataFrame(scaler_test.transform(test), columns = test.columns)\n",
    "\n",
    "# Variable list from https://www.nbi.dk/~petersen/Teaching/ML2023/InitialProject/VariableList.html\n",
    "all_variables = ['actualInteractionsPerCrossing', 'averageInteractionsPerCrossing', 'correctedActualMu', 'correctedAverageMu', 'correctedScaledActualMu', 'correctedScaledAverageMu', 'NvtxReco', 'p_nTracks', 'p_pt_track', 'p_eta', 'p_phi', 'p_charge', 'p_qOverP', 'p_z0', 'p_d0', 'p_sigmad0', 'p_d0Sig', 'p_EptRatio', 'p_dPOverP', 'p_z0theta', 'p_etaCluster', 'p_phiCluster', 'p_eCluster', 'p_rawEtaCluster', 'p_rawPhiCluster', 'p_rawECluster', 'p_eClusterLr0', 'p_eClusterLr1', 'p_eClusterLr2', 'p_eClusterLr3', 'p_etaClusterLr1', 'p_etaClusterLr2', 'p_phiClusterLr2', 'p_eAccCluster', 'p_f0Cluster', 'p_etaCalo', 'p_phiCalo', 'p_eTileGap3Cluster', 'p_cellIndexCluster', 'p_phiModCalo', 'p_etaModCalo', 'p_dPhiTH3', 'p_R12', 'p_fTG3', 'p_weta2', 'p_Reta', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_f3', 'p_Rhad', 'p_Rhad1', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_TRTPID', 'p_TRTTrackOccupancy', 'p_numberOfInnermostPixelHits', 'p_numberOfPixelHits', 'p_numberOfSCTHits', 'p_numberOfTRTHits', 'p_numberOfTRTXenonHits', 'p_chi2', 'p_ndof', 'p_SharedMuonTrack', 'p_E7x7_Lr2', 'p_E7x7_Lr3', 'p_E_Lr0_HiG', 'p_E_Lr0_LowG', 'p_E_Lr0_MedG', 'p_E_Lr1_HiG', 'p_E_Lr1_LowG', 'p_E_Lr1_MedG', 'p_E_Lr2_HiG', 'p_E_Lr2_LowG', 'p_E_Lr2_MedG', 'p_E_Lr3_HiG', 'p_E_Lr3_LowG', 'p_E_Lr3_MedG', 'p_ambiguityType', 'p_asy1', 'p_author', 'p_barys1', 'p_core57cellsEnergyCorrection', 'p_deltaEta0', 'p_deltaEta2', 'p_deltaEta3', 'p_deltaPhi0', 'p_deltaPhi1', 'p_deltaPhi2', 'p_deltaPhi3', 'p_deltaPhiFromLastMeasurement', 'p_deltaPhiRescaled0', 'p_deltaPhiRescaled1', 'p_deltaPhiRescaled3', 'p_e1152', 'p_e132', 'p_e235', 'p_e255', 'p_e2ts1', 'p_ecore', 'p_emins1', 'p_etconeCorrBitset', 'p_ethad', 'p_ethad1', 'p_f1core', 'p_f3core', 'p_maxEcell_energy', 'p_maxEcell_gain', 'p_maxEcell_time', 'p_maxEcell_x', 'p_maxEcell_y', 'p_maxEcell_z', 'p_nCells_Lr0_HiG', 'p_nCells_Lr0_LowG', 'p_nCells_Lr0_MedG', 'p_nCells_Lr1_HiG', 'p_nCells_Lr1_LowG', 'p_nCells_Lr1_MedG', 'p_nCells_Lr2_HiG', 'p_nCells_Lr2_LowG', 'p_nCells_Lr2_MedG', 'p_nCells_Lr3_HiG', 'p_nCells_Lr3_LowG', 'p_nCells_Lr3_MedG', 'p_pos', 'p_pos7', 'p_poscs1', 'p_poscs2', 'p_ptconeCorrBitset', 'p_ptconecoreTrackPtrCorrection', 'p_r33over37allcalo', 'p_topoetconeCorrBitset', 'p_topoetconecoreConeEnergyCorrection', 'p_topoetconecoreConeSCEnergyCorrection', 'p_weta1', 'p_widths1', 'p_widths2', 'p_wtots1', 'p_e233', 'p_e237', 'p_e277', 'p_e2tsts1', 'p_ehad1', 'p_emaxs1', 'p_fracs1', 'p_DeltaE', 'p_E3x5_Lr0', 'p_E3x5_Lr1', 'p_E3x5_Lr2', 'p_E3x5_Lr3', 'p_E5x7_Lr0', 'p_E5x7_Lr1', 'p_E5x7_Lr2', 'p_E5x7_Lr3', 'p_E7x11_Lr0', 'p_E7x11_Lr1', 'p_E7x11_Lr2', 'p_E7x11_Lr3', 'p_E7x7_Lr0', 'p_E7x7_Lr1' ]\n",
    "\n",
    "\n",
    "X_train = train[all_variables][:130000]\n",
    "y_train = train['p_truth_E'][:130000]\n",
    "X_validate = train[all_variables][130000:]\n",
    "y_validate = train['p_truth_E'][130000:]\n",
    "X_test = test[all_variables]\n",
    "\n",
    "with open('Classification_JuliusFoverskov_XGBoost_VariableList.txt','r') as f:\n",
    "    sorted_variables = [item.strip() for item in f]\n",
    "\n",
    "# Only pick 15 most important features for clustering, importances optained from permutation importance\n",
    "sorted_variables = sorted_variables[:15]\n",
    "\n",
    "X_train = X_train[sorted_variables]\n",
    "X_validate = X_validate[sorted_variables]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe4319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_train = lgb.Dataset(X_train, label=y_train)\n",
    "params = {'objective': 'regression',\n",
    "          'boosting_type': 'gbdt',\n",
    "          'metric': 'mean_squared_error',\n",
    "          'learning_rate': 0.01,\n",
    "          'num_leaves': 10,\n",
    "          'max_depth': 10,\n",
    "          'min_data': 10,\n",
    "          'verbose': 0,\n",
    "          'force_col_wise': True}\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "lgb_clf = lgb.train(params, train_set=data_train, num_boost_round=300)\n",
    "y_pred = np.around(lgb_clf.predict(X_train.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db3bcbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1780767430.2134445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([158135.40980146, 121317.87191535, 154378.98803863, ...,\n",
       "       101112.45879904,  44745.62876193, 183020.86905364])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming you have trained a LightGBM model and have the predictions and ground truth\n",
    "y_pred = lgb_clf.predict(X_validate)  # Replace X_test with your test data\n",
    "mse = mean_squared_error(y_validate, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "preds = lgb_clf.predict(X_test[sorted_variables])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957325a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e860e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to a file\n",
    "\n",
    "# Probabilities of particle being an electron\n",
    "with open('Regression_JuliusFoverskov_LightGBM.txt','w') as f:\n",
    "    for index, prediction in zip(X_test.index, preds):\n",
    "        f.write(f\"{index}, {prediction}\\n\")\n",
    "\n",
    "# List of most important features from permutation importance for electron classification\n",
    "with open('Regression_JuliusFoverskov_LightGBM_VariableList.txt','w') as f:\n",
    "    f.write(\"\\n\".join(map(str, sorted_variables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7226c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
